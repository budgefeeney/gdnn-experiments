{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rr941ikUePO"
   },
   "source": [
    "# Abstract\n",
    "\n",
    "This is a simple restatement of the VAE MNist tutorial from the Keras documentation at:\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_add_loss_method\n",
    "\n",
    "It was found by looking at this Stackoverflow question where the answerer (obliquely) suggested that there can be issues with feeding in tfvars into loss functions at the last minute, even via Lambdas\n",
    "\n",
    "https://stackoverflow.com/questions/62766042/inputs-to-eager-execution-function-cannot-be-keras-symbolic-tensors-with-variati\n",
    "\n",
    "> I've been having the same problem for a long time, but managed to figure it out. The problem is that TF only accepts loss functions which accept (input, output) parameters which are then compared. However, you are computing your (kl_)loss using also mu and sigma, which are basically dense layers. Until tensorflow v2.1 it magically knew what these parameters were and knew how to include/manipulate them, but from then on, you have to be more careful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXHZ6v2XU43U"
   },
   "source": [
    "# Layers API\n",
    "\n",
    "The tutorial is about the layers API. A Layer has, among other things\n",
    "\n",
    "1. An `__init__()` constructor which absorbs the usual parameters (e.g. `units`)\n",
    "2. A `call()` method that does the work of the layer: strictly, for neural-networks layers, this is the implementation of the forward pass.\n",
    "3. A `build()` method called just before the first call to `call()` which can be used to lazily instantiate the tfvars that make the `Layer`. These tfvars can be marked as trainable or not.\n",
    "4. A `__call__()` method which actually does the work when you do `m = MyLayer(**params); m(x)`. Among other things, this obviously checks does it need to call `build()` and will at some point call `call()`. \n",
    "5. An `add_weight()` method is inherited to simplify adding tfvars\n",
    "6. An `add_loss()` method can be used to add a layer-specific loss. Typically this is the regularlization loss.\n",
    "\n",
    "You can compose layers together, which is how you can add an activation layer into your `Dense` layer when you use the `activation` parameter.\n",
    "\n",
    "Or in our case, create a custom sampling layer which keeps track of the KL loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZUJwCLWWBjA"
   },
   "source": [
    "# VAE MNIST Example:  Object-Orientated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2256,
     "status": "ok",
     "timestamp": 1612994500528,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "8zR5KZy6WAza"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple, List, Union, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from tensorflow.keras import backend as K  # tensor operations\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_dim,\n",
    "        intermediate_dim=64,\n",
    "        latent_dim=32,\n",
    "        name=\"autoencoder\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31043,
     "status": "ok",
     "timestamp": 1612994529320,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "G8pBxdDuU3dm",
    "outputId": "91730280-c20b-484c-97a3-1f943853ba0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "Start of epoch 0\n",
      "step 0: mean loss = 0.3845\n",
      "step 100: mean loss = 0.1276\n",
      "step 200: mean loss = 0.1003\n",
      "step 300: mean loss = 0.0899\n",
      "step 400: mean loss = 0.0848\n",
      "step 500: mean loss = 0.0813\n",
      "step 600: mean loss = 0.0791\n",
      "step 700: mean loss = 0.0775\n",
      "step 800: mean loss = 0.0763\n",
      "step 900: mean loss = 0.0752\n",
      "Start of epoch 1\n",
      "step 0: mean loss = 0.0749\n",
      "step 100: mean loss = 0.0742\n",
      "step 200: mean loss = 0.0737\n",
      "step 300: mean loss = 0.0732\n",
      "step 400: mean loss = 0.0729\n",
      "step 500: mean loss = 0.0725\n",
      "step 600: mean loss = 0.0722\n",
      "step 700: mean loss = 0.0719\n",
      "step 800: mean loss = 0.0716\n",
      "step 900: mean loss = 0.0714\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = MeanSquaredError()\n",
    "\n",
    "loss_metric = metrics.Mean()\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(epochs):\n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed = vae(x_batch_train)\n",
    "            # Compute reconstruction loss\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36483,
     "status": "ok",
     "timestamp": 1612994534767,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "L-ydrpMCXhlP",
    "outputId": "2bcf3662-aeb6-4482-9461-75dc2ea2a354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 2s 1ms/step - loss: 0.0954\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f29100e8c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploit the the fact that VariationalAutoEncoder subclasses Model to make life easier\n",
    "\n",
    "vae = VariationalAutoEncoder(784, 64, 32)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())  # 👈 custom loss is added in automatically...\n",
    "vae.fit(x_train, x_train, epochs=2, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRnBNq2dX2Jz"
   },
   "source": [
    "# VAE MNIST with the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8066,
     "status": "ok",
     "timestamp": 1612994597098,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "-6SK_gMMX1nR",
    "outputId": "a4ba3c5c-d12b-4288-cdde-d94692d9bf61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1116\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0675\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f289c248040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dim = 784\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "# Define encoder model.\n",
    "original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n",
    "\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n",
    "\n",
    "# Define decoder model.\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation=\"sigmoid\")(x)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n",
    "\n",
    "# Define VAE model.\n",
    "outputs = decoder(z)\n",
    "vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n",
    "\n",
    "# Add KL divergence regularization loss.\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae.add_loss(kl_loss)  # 👈 Using this seems to be the key to avoiding losing graph connection in loss fn.\n",
    "\n",
    "# Train.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "vae.fit(x_train, x_train, epochs=3, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1612994601711,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "4W2cbRz39lkR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1612994629619,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "chmkSAA4XtB2",
    "outputId": "0f50fac9-1219-45d3-a81f-128027f03d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f289c3de130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "  np.squeeze(\n",
    "    decoder.predict(\n",
    "      np.array(\n",
    "        [[-2, -2]]\n",
    "      )\n",
    "    )\n",
    "  ).reshape((28, 28))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44305,
     "status": "aborted",
     "timestamp": 1612994542604,
     "user": {
      "displayName": "Bryan Feeney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiPntWv82gXOOwC1JBFNoK4SPM-4IxTQnERyCBuUQ=s64",
      "userId": "15000880758463632242"
     },
     "user_tz": 0
    },
    "id": "AVoPVi6k9kk1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPHcdaK6r5Ke3cNu23te1sS",
   "name": "Keras MNist VAE Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
